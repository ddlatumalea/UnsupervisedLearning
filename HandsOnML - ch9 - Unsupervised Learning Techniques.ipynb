{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e691fc",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Techniques\n",
    "\n",
    "**Clustering**: grouping similar instances into clusters.\n",
    "\n",
    "**Anomaly detection**: objective to learn what \"normal\" data looks like, and use it to detect abnormal instances.\n",
    "\n",
    "**Density estimation**: estimating the probability density function (PDF) of the random process that generated the dataset. Useful for data analysis, visualization and detecting anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd7a0a",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "Works well with multiple features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc5436",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "\n",
    "X_new = ...\n",
    "kmeans.predict(X_new)\n",
    "\n",
    "# measure distance from each instance to every centroid\n",
    "kmeans.transform(X_new)\n",
    "```\n",
    "\n",
    "Properties:\n",
    "- An instance's *label* is the index of the cluster that the instance gets assigned to.\n",
    "\n",
    "You can plot the decision boundaries to get a *Voronoi tessellation*.\n",
    "\n",
    "**Hard clustering**: assigning each instance to a single cluster.\n",
    "\n",
    "**Soft clustering**: giving each instance a score per cluster.\n",
    "\n",
    "**Normal Algorithm**:\n",
    "- Place centroid randomly, label instances, update centroid, label, etc. until centroids stop moving.\n",
    "- Can get stuck into a local optimum if you are not lucky with the random initialization step.\n",
    "- sklearn uses the `n_init` parameter to run the model multiple times and keep the model with the best performance (lowest inertia). The `score` is negative, as it respects the *\"great is better\"* rule.\n",
    "\n",
    "**K-Means++**:\n",
    "- Take one centroid $c^{(1)}$, chosen uniformly at random from the dataset.\n",
    "- Take a new centroid $c^{(i)}$, choosing an instance $x^{(i)}$ with probability $D(x^{(i)})^2 \\Sigma^m_{j=1}D(x^{(j)})^2$ where $D(x^{(i)}$ is the distance between the instance $x^{(i)}$ and the closest centroid that was already chose. This distribution ensures that instances further away from already chosen centroids are more likely to be selected as centroids.\n",
    "- Repeat until all $k$ centroids have been chosen.\n",
    "\n",
    "**MiniBatchKMeans**:\n",
    "- Speed up KMeans by a factor 3/4 and make it posible to cluster huge data.\n",
    "- Intertia is generally slightly worse.\n",
    "- `partial_fit` can be used, but using `memmap` class is easiest.\n",
    "\n",
    "```python\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=k)\n",
    "minibatch_kmeans.fit(X)\n",
    "```\n",
    "\n",
    "**Selecting number of clusters**:\n",
    "- Use elbow rule, as picking the lowest inertia won't make sense, as it will keep decreasing.\n",
    "    - Rough estimation.\n",
    "- Silhouette score.\n",
    "    - More precise (but more computationally expensive)\n",
    "    - Mean of the *silhouette coefficient*.\n",
    "    - *silhouette coefficient*: $(b-a)/max(a,b)$ where $a$ is mean distance to other instances in the same cluster, and $b$ is the mean nearest-cluster distance.\n",
    "    - Score between -1 and +1. \n",
    "        - Close to +1 means the instance is well inside its own cluster and far from other clusters.\n",
    "        - 0 means that is close to a cluster boundary.\n",
    "        - -1 means that the instance may have been assigned to the wrong cluster.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import silhoutte_score\n",
    "\n",
    "silhouette_score(X, kmeans.labels_)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0976a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
